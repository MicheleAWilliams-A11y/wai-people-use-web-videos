---
title: "Video Script for Auditory"

lang: en   # Change "en" to the translated-language shortcode from https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry
last_updated: 2022-10-08   # Put the date of this translation YYYY-MM-DD (with month in the middle)

github:
  repository: w3c/wai-people-use-web-videos
  path: content/index.md    # Add the language shortcode to the middle of the filename, for example: content/index.fr.md
permalink: /people-use-web/videos/abilities/auditory/   # Add the language shortcode to the end, with no slash at end, for example: /link/to/page/fr

ref: /people-use-web/videos/abilities/auditory/   # Translators, do not change this

description: draft video scripts for Auditory from the WAI resource "How People with Disabilities Use the Web"

footer: >
   <p><strong>Date:</strong> Updated 8 October 2022.</p>

---

**[Back to Index Page](../../)**

Video script for [Auditory](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/abilities-barriers-auditory/) from the page [Diverse Abilities and Barriers](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/abilities-barriers/) (in the [2020 Update](https://github.com/w3c/wai-people-use-web/wiki/Persona-development) version).

**[Submit an Issue](https://github.com/w3c/wai-people-use-web-videos/issues/new?title=[Auditory])**

## Script

| Seq. | Time | Audio | Visual |
| --- | --- | --- | --- |
| 0 | 0:00 - 0:00 | How people with disabilities use the web; auditory disabilities. | [Front plate.] box with the text "Auditory Disabilities". |
| 1 | 0:00 - 0:00 | Auditory disabilities affect how people hear, including hearing less in one or both ears, not hearing, and hearing sounds in a range of different ways. | We see a collage of five people going about their lives in their different settings [they are the protagonists that we will see in the coming scenes]. |
| 2 | 0:00 - 0:00 | High-quality sound is important for many people with reduced hearing. This includes clear audio and low background noise, to make speech in the audio easier to understand. Websites and apps that allow users to adjust the volume of the audio that it is currently playing without changing the volume for all other sounds from the computer also make it easier for people to hear the audio. | [New scene; zoom into the context/setting of one of the people (#11) shown in the collage in the previous scene.] We see the person (#11) watching a speech (e.g. talking-head video) embedded on a web page. [there is no visible indication that the person (#11) has any disability]. We see the person (#11) adjust the volume of the video independently from other computer audio [we see a sound mixer widget with multiple volume sliders, and the person is adjusting one of the volume sliders on the mixer]. |
| 3 | 0:00 - 0:00 | Some people with auditory disabilities use hearing devices. Yet this does not always mean they can hear all audio, or hear it clearly. Websites and apps that do not rely on audio alone, for example by using visual alerts in addition to audio, make it easier for people with different types of auditory disabilities to perceive the information. | [New scene.] We see the person (#10) is using a computer. We see a visual alert from the website that the person (#10) is using appear on the screen (e.g. that a new message arrived). We see the person (#10) from a different angle and realize that the person (#10) has a cochlear implant. |
| 4 | 0:25 - 0:50 | Another example of visual alternatives to audio are captions. Captions provide important audio information in text format. They indicate who is speaking and important sounds, such as the creaking sound of a door in a horror movie. Many people who use captions also need to adjust the text size, font, and color to make the captions more readable. | [New scene.] We see the person (#12) watching a movie (eg. thriller) and turning on the captions. We see that the person (#12) is using a hearing device. We focus on the captions and see that they reflect the creaking door in the text. |
| 5 | 0:50 - 1:10 | While automatic captions are gradually improving, they are usually too inaccurate to rely on as an alternative. For example, they don't recognize specialized terms well, and the sentences can sometimes run together making it hard to keep up. | [Continuation from previous scene.] We see the person (#12) switch to another video, and turn on automatic captions for that second video. The captions are clearly inaccurate (e.g. sentence with words that are obviously misheard) and the person (#12) is looking confused / frustrated. |
| 6 | 1:30 - 2:00 | While many people with auditory disabilities do not use sign language, for many it is the primary language for communication. Not only are there different sign languages per country and even per region or culture, sign language is also very different from written and spoken language. That means people are often translating between sign language and written language, and peopleâ€™s levels of understanding written language can vary. In order to see sign language clearly, people rely on high-quality video transmissions. This includes needing access to high-speed internet and devices that can handle high-quality video. | [New scene; switch to person (#6/Martine) who is featured in a separate video (see [Martine's script](https://wai-people-use-web-videos.netlify.app/people-use-web/videos/stories/martine/)).] We see the person (#6/Martine) in an online meeting, conversing with her peers through sign language interpreters on the call. We see the sign language interpreters sign to the person (#6/Martine), and the person (#6/Martine) nodding/signing/gesturing back to signal acknowledgment to the interpreters and to continue the conversation with her peers. |
| 7 | 2:00 - 2:40 | Finally, people auditory disabilities also includes people who are deaf-blind. That is, people with varying degrees of reduced hearing and vision. Most people who are deaf-blind rely on communication that is tactile, like braille. For example, portable braille displays can convert text on the computer to braille letters that can be felt on the fingertips. And for multimedia, like videos, people rely on descriptive transcripts. This is text, such as an article or script, that contains all the audio and visual information so that the information is understood without watching the video. | [New scene; switch to person (#7/Noor) who is featured in a separate video (see [Noor's script](https://wai-people-use-web-videos.netlify.app/people-use-web/videos/stories/noor/)).] We see the person (#7/Noor) using a portable braille display to read what's on the screen. [We see the screen turned off]. The person (#7/Noor) is scanning the braille display with their finger tips, and switching to the keyboard to type. |
| 8 | 0:00 - 0:00 | [Individual protagonists:] These are ways to make technology work for me. [Narrator:] Accessibility: It's about people. | [New scene.] We see the five protagonists from the previous scenes. They are looking into the camera as they speak their lines to the viewers [either individually or all at the same time, to be decided]. We see more and more protagonists from the other videos appear on the screen [to illustrate many people] as the narrator speaks their line. |
| 9 | 0:00 - 0:00 | For more information on how people with disabilities use the web, visit w3.org/WAI | [End plate.] We see the URL from the narration. |
