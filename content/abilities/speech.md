---
title: "Video Script for Speech"

lang: en   # Change "en" to the translated-language shortcode from https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry
last_updated: 2022-08-15   # Put the date of this translation YYYY-MM-DD (with month in the middle)

github:
  repository: w3c/wai-people-use-web-videos
  path: content/index.md    # Add the language shortcode to the middle of the filename, for example: content/index.fr.md
permalink: /people-use-web/videos/abilities/speech/   # Add the language shortcode to the end, with no slash at end, for example: /link/to/page/fr

ref: /people-use-web/videos/abilities/speech/   # Translators, do not change this

description: draft video scripts for Speech from the WAI resource "How People with Disabilities Use the Web"

footer: >
   <p><strong>Date:</strong> Updated 15 August 2022.</p>

---

**[Back to Index Page](../../)**

Video script for [Speech](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/abilities-barriers-speech/) from the page [Diverse Abilities and Barriers](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/abilities-barriers/) (in the [2020 Update](https://github.com/w3c/wai-people-use-web/wiki/Persona-development) version).

**[Submit an Issue](https://github.com/w3c/wai-people-use-web-videos/issues/new?title=[speech])**

## Summary

* Narrated video (using voice-over to explain)

## Script

| Seq. | Time | Audio | Visual |
| --- | --- | --- | --- |
| 1 | 0:00 - 0:00 | Speech disabilities includes people who speak differently or who do not speak at all. | We see a collage of five people going about their lives in their different settings [they are the protagonists that we will see in the coming scenes]. |
| 2 | 0:00 - 0:00 | For example, some people might stutter, pause, and pronounce sounds differently. [brief pause to listen to the protagonist say something like "while you can understand me, speech recognition systems often don't" (the protagonist has a mild speech disability that most viewers/listners would understand).] | [New scene; zoom into the context/setting of one of the people (#1) shown in the collage in the previous scene.] We see person (#1) first typing on a computer then turning to us (the viewers/camera) to speak the words we hear in the audio. We see a digital assistant (e.g. something that looks like Google Assistant or Alexa Echo) nearby but dissociated from person (#1) (e.g. on someone else's desk).  |
| 3 | 0:00 - 0:00 | Speaking differently is not an indication of the person's intellectual capabilities. | [Continuation from previous scene.] We see the person (#1) getting up and move around, and we realize the person (#1) is a researcher in a laboratory (or similar). |
| 4 | 0:00 - 0:00 | Some people do not speak at all, for example because they are Deaf, have injured or no vocal organs, or because of another physical condition. | [New scene; switch to person (#2/Martine) who will be featured in a separate video (see [Martine's story page](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories-six/)).] We see person (#2/Martine) in an online meeting and signing to communicate with others in the meeting. [This scene is similar to scene 2 in the [Martine script](https://wai-people-use-web-videos.netlify.app/people-use-web/videos/stories/martine/).] |
| 5 | 0:00 - 0:00 | Using speech alone is barrier for many people; for example, when telephone services and online applications, such as customer support, rely on automatic speech recognition without alternative ways for communication. | [New scene.] We see a person (#3) [there is no visible indication that the person (#3) has any disability] using a website or app and trying to contact customer support but the only available mechanism is a call-back option. Person (#3) is looking confused / frustrated. |
| 6 | 0:00 - 0:00 | Some people use assistive devices to generate speech, which might also not work well with automatic speech recognition either. For example, some use "speech generated by a computer" [speech synthesis coming from a computer, sounding like that of Stephen Hawking] or devices like an electrolarynx, which "converts vibrations on the throat to sound" [speech coming from an electrolarynx device]. | [New scene.] We see two people (#4) and (#5), one after the other (that is, two different sub-scenes that are intertwined). [First sub-scene] We see person (#4) typing some text on a computer, then we swing over from the typing to see what the person (#4) typed while we hear the generated audio coming out of the loud speaker. [Second sub-scene] We see person (#5) speaking to us (the viewers/camera) by holding an electrolarynx device to the throat and speaking the words we hear. |
| 7 | 0:00 - 0:00 | All this has one thing in common: your design can include or exclude people. | [New scene.] We see a collage of the five protagonists from the previous scenes [in the same style and continuing the first scene] happily using computer technologies [each person's setting is a continuation of their respective scenes]. |
