---
title: "Video Script for Perception"

lang: en   # Change "en" to the translated-language shortcode from https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry
last_updated: 2022-08-11   # Put the date of this translation YYYY-MM-DD (with month in the middle)

github:
  repository: w3c/wai-people-use-web-videos
  path: content/index.md    # Add the language shortcode to the middle of the filename, for example: content/index.fr.md
permalink: /people-use-web/videos/tools/perception/   # Add the language shortcode to the end, with no slash at end, for example: /link/to/page/fr

ref: /people-use-web/videos/tools/perception/   # Translators, do not change this

description: draft video scripts for Perception from the WAI resource "How People with Disabilities Use the Web"

footer: >
   <p><strong>Date:</strong> Updated 11 August 2022.</p>

---

**[Back to Index Page](../../)**

Video script for [Perception](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/tools-techniques-perception/) from the page [Tools and Techniques](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/tools-techniques/) (in the [2020 Update](https://github.com/w3c/wai-people-use-web/wiki/Persona-development) version).

**[Submit an Issue](https://github.com/w3c/wai-people-use-web-videos/issues/new?title=[Perception])**

## Summary

* Narrated video (using voice-over to explain)

## Script

| Seq. | Time | Audio | Visual |
| --- | --- | --- | --- |
| 1 | 0:00 - 0:00 | People perceive information through different senses. This includes perceiving information through hearing, seeing, and feeling. | We see a collage of four people going about their lives in their different settings [they are the protagonists that we will see in the coming scenes]. |
| 2 | 0:00 - 0:00 | Consider, for example, people who are blind or have low vision; many rely on hearing or feeling the information instead of seeing it. Many use audio description tracks when they are provided by video content authors. Audio descriptions often use pauses in the audio track to describe the scenes, characters, and other visual information in the video. [brief pause to listen to a short slice of audio descriptions while the video is being shown in the visuals] | [New scene; zoom into the context/setting of one of the people (#1/Ilya) shown in the collage in the previous scene but we focus more on the technology rather than on the person; Ilya will be featured in a separate video too (see [Ilya's story page](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories-three/)).] We see person (#1/Ilya) starting a video and switching on the "Audio Description" feature. We see brief part of the video that Ilya start while we hear the audio descriptions for that scene. |
| 3 | 0:00 - 0:00 | Many also use assistive technology called screen readers. These software tools capture information on the screen and convert it to audio to hear, or convert it to braille letters on a refreshable braille display. Every braille letter is a combination of eight dots. Each of the eight dots is raised or lowered in a particular pattern to represent a letter. People run their fingertips over these dots to read the braille letters, one line at a time. | [Continuation from previous scene.] We see person (#1/Ilya) leave the video and continue to read on the text on the page. We focus on the refreshable braille display as the narration explains it. We focus further on the individual braille letters as the narration continues. |
| 4 | 0:00 - 0:00 | However, for screen readers to work, content needs to be properly programmed and designed. For example, images need to have text alternatives, so that screen readers can convey the text alternatives to audio or to braille. Also, headings, tables, lists and other structures need to be properly coded, so that screen readers can identify and indicate these structures to the user. | [Continuation from previous scene.] We swing over from the refreshable braille display to the computer screen. We scan over the content with the images, headings, tables, and lists, appearing as the narration mentions them. |
| 5 | 0:00 - 0:00 | People who are Deaf and Hard of Hearing often also rely on feeling; for example, by using vibration alerts on a mobile phone instead of audio notifications. | [New scene; switch to person (#2) who also happens to be person #2 in the [Auditory script](https://wai-people-use-web-videos.netlify.app/people-use-web/videos/abilities/auditory/).] We see the phone of person (#2) vibrating when a notification appears on the screen. The attention of person #2 is drawn to the phone because of the vibration. |
| 6 | 0:00 - 0:00 | Many also rely on seeing instead of hearing; for example, by using captions and sign language when they are provided by audio content authors. | [New scene; switch to person (#3/Martine) who will be featured in a separate video (see [Martine's story page](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories-six/)).] We see person (#3/Martine) in an online meeting with sign language interpreters pinned and with captions turned on. This scene is similar to scene 2 in the [Martine script](https://wai-people-use-web-videos.netlify.app/people-use-web/videos/stories/martine/). |
| 7 | 0:00 - 0:00 | In some cases, people with reading disabilities might also need to convert text and functionality to symbols that they can better understand. Symbols could be pictures of the words; for example, a picture of an apple instead of the word "apple". They can also be recognizable illustrations for certain functionality, such as a home icon to symbolize "back to home" functionality, or a cash icon to symbolize "purchase" functionality. | [New scene; switch to another person (#4) who will likely be featured in the "Cognitive, learning, and neurological" video (see [Cognitive, learning, and neurological page](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/abilities-barriers-cognitive/)).] We see person (#4) using adaptation tools to show symbols instead of text. The focus is more on the symbols on the screen appearing in sequence with the narration rather than on the person. |
| 8 | 0:00 - 0:00 | All this has one thing in common: your design can include or exclude people. | [New scene.] We see a collage of the four protagonists from the previous scenes [in the same style and continuing the first scene] happily using computer technologies [each personâ€™s setting is a continuation of their respective scenes]. |
