---
title: "Video Script for Ilya"

lang: en   # Change "en" to the translated-language shortcode from https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry
last_updated: 2022-08-22   # Put the date of this translation YYYY-MM-DD (with month in the middle)

github:
  repository: w3c/wai-people-use-web-videos
  path: content/index.md    # Add the language shortcode to the middle of the filename, for example: content/index.fr.md
permalink: /people-use-web/videos/stories/ilya/   # Add the language shortcode to the end, with no slash at end, for example: /link/to/page/fr

ref: /people-use-web/videos/stories/ilya/   # Translators, do not change this

description: draft video scripts for Ilya from the WAI resource "How People with Disabilities Use the Web"

footer: >
   <p><strong>Date:</strong> Updated 22 August 2022.</p>

---

**[Back to Index Page](../../)**

Video script for [Ilya](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories-three/) from the page [Stories of Web Users](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories/) (in the [2020 Update](https://github.com/w3c/wai-people-use-web/wiki/Persona-development) version).

**[Submit an Issue](https://github.com/w3c/wai-people-use-web-videos/issues/new?title=[Ilya])**

## Summary

* Female
* Adult
* Blind (acquired)
* Uses computer
* Uses mobile phone
* Uses screen reader
* Uses text-to-speech

## Script

| Seq. | Time | Audio | Visual |
| --- | --- | --- | --- |
| 1 | 0:00 - 0:00 | Hello! I'm Ilya. I lost my sight due to Diabetes Type I during my childhood, and have been blind since. | We see Ilya speaking directly to us viewers [documentary style into the camera]. We briefly see a total of Ilya. [Viewers might notice that she is not looking directly into the camera because she does not see it, or other aspects of her disability.] |
| 2 | 0:00 - 0:00 | I use a screen reader to access digital content. It's a software that reads out the information on the screen. This includes text but it also announces the headings in a document, lists and how many list items they have, and tables and controls and such. It's like an assistant describing everything on the screen to me. Only much quicker [brief pause to listen to a short slice of screen reader at moderately high speed while the video is being shown in the visuals]. I've learned to scan such audio over the years, just like others might speed-read visually by scanning the text. | [New scene.] We see Ilya in a work enviroment (e.g. home office or office) with wired headphones connected to a computer. We scan over headings, lists, tables, and controls on the screen as the narrator mentions them. We stop at the brief piece of text as it is being read aloud (e.g. form instruction, input confirmation, or other brief piece of text). |
| 3 | 0:00 - 0:00 | Some screen readers are quite complex and take a lot of time to learn properly. Today there are more options, including screen readers built directly into mobile phones and computers. Actually, I'd use my phone for everything but I need to use my computer for work. This means learning and using two different screen readers, each with their own functions and quirks. | [New scene.] We see Ilya in a casual environment (e.g. at home or at a cafe etc.) with wireless headphones and using a mobile phone. We see her swiping, tapping, and gesturing one a screen that is turned off. She is listening attentively, as she was at work. |
| 4 | 0:00 - 0:00 | A few years ago the company I work for changed the desktop applications to online applications. I was really concerned about that move because of the many online spreadsheets, presentations, and documents that I need to use and edits -- complex online applications often get challenging and are not accessible. Luckily, the company paid attention to that aspect during procurement and selected a provider that ensured accessibility. | [New scene; continuation of Scene 2 where Ilya is at work.] We see Ilya back at work navigating through a complex online application (e.g. a document management system with a dense hierarchical navigation with lots of filenames being listed). We see her opening menu items and sub-items, and moving through tree-view structures and dialog windows. |
| 5 | 0:00 - 0:00 | The only issue is the online conferencing tool that our client uses. Unfortunately, many of the buttons are not properly labeled so I don't know which is which. I memorized the "join" and "leave" buttons but cannot participate in the chat. It doesn't even notify me when there are new messages or who a message is from. | [Continuation from previous scene.] We see Ilya starting an online conferencing tool. We see her navigate to the "join" button and press it to enter a meeting. We see the chat area fill up with the names of the attendees and with messages that are being typed as the narration speaks [we don't really see the actual chat messages as closely, just that there is activity happening without Ilya]. |
| 6 | 0:00 - 0:00 | Outside work, one of the biggest barriers for me are CAPTCHAS -- you know, these login screens where you have to prove that you're a human. Well, I **am** human! It's so humiliating and disruptive to have to get help, and there isn't always someone around that I want to get help from. I know it can be done differently because other websites have other options -- for example, they verify by email or text message. | [New scene; continuation of Scene 3 where Ilya is at home.] We see Ilya frustrated (maybe somewhat angry too). We see her turn the screen on and hand the phone to someone next to her (e.g. partner, child, room mate, ...) who completes the CAPTCHA for her [we don't hear what they speak, just see the interaction between the two]. |
| 7 | 0:00 - 0:00 | All this has one thing in common: your design can include or exclude people. | [New scene.] We see Ilya speaking directly to us, as in the first scene [documentary style into the camera, in the same style and continuing the first scene]. |
