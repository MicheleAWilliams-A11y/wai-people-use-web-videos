---
title: "Video Script for Martine"

lang: en   # Change "en" to the translated-language shortcode from https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry
last_updated: 2022-04-14   # Put the date of this translation YYYY-MM-DD (with month in the middle)

github:
  repository: w3c/wai-people-use-web-videos
  path: content/index.md    # Add the language shortcode to the middle of the filename, for example: content/index.fr.md
permalink: /people-use-web/videos/stories/martine/   # Add the language shortcode to the end, with no slash at end, for example: /link/to/page/fr

ref: /people-use-web/videos/stories/martine/   # Translators, do not change this

description: draft video scripts for Martine from the WAI resource "How People with Disabilities Use the Web"

footer: >
   <p><strong>Date:</strong> Updated 14 April 2022.</p>

---

**[Back to Index Page](../../)**

Video script for [Martine](https://deploy-preview-113--wai-people-use-web.netlify.app/people-use-web/user-stories-six/) from the page [Stories of Web Users](https://www.w3.org/WAI/people-use-web/user-stories/) (in the [2020 Update](https://github.com/w3c/wai-people-use-web/wiki/Persona-development) version).

**[Submit an Issue](https://github.com/w3c/wai-people-use-web-videos/issues/new?title=[Martine])**

## Summary

* Older adult
* Female
* Deaf
* Hears some sounds
* Reads lips
* Needs captions
* Needs easier to read text
* Uses sign language
* Uses video relay service
* Uses video conferencing
* Student
* Takes online courses

## Script

| Seq. | Time | Audio | Visual |
| --- | --- | --- | --- |
| 1 | 0:00 - 0:15 | Hello! I'm Martine. I'm legaly deaf, which means that I can hear some sounds but not enough to understand speech. [British/American/TBD] sign language is my primary language since childhood -- I think and dream in signs. | We see Martine signing directly to us viewers (documentary style into the camera). We briefly see that she is communicating through a sign language interpreter who is speaking what she signs (the audio we hear). |
| 2 | 0:15 - 0:35 | I recently enrolled in an online degree. For my classes, I schedule interpreters who sign the conversations and speak aloud my comments. For this, I need meeting apps with functionality to "pin" videos of the interpreters so that I can always see them. | [New scene.] We see Martine in a video conference meeting with multiple people online. We see two sign language interpreters join the meeting (the windows for the interpreters are labeled accordingly, and we see Martine take particular attention to these two windows). We see Martine use a "pin to screen" function for the interpreters and for the current speaker. We see her signing back to the interpreter to speak up in the meeting. We don't really see the exact signs or hear the interpreter while the scene transitions, we just see that she is actively participating in the meeting. |
| 3 | 0:35 - 1:15 | Some lectures have realtime captioning by real humans. This is more accurate than automatic captions, which donâ€™t recognize specialized terms and names, make it hard to tell who is speaking, and can run sentences together making it hard to keep up. For our assigned videos, however, I rely on closed captions. These are edited so that they are not too long and are properly synchronized with the audio. And because none of us are getting any younger, you know, I often find myself needing to adjust the text size and colors of captions, to be able to read them better. Some apps also allow me to move the captions to the top or bottom of the video, so that they are not in the way. | [New scene.] We see Martine watching an online lecture with captions. [We see that the captions indicate who is speaking but don't see enoughto actually read the entire text.] We see Martine switching from the live lecture to a pre-recorded video (e.g. browse through a collection of videos and select one of them). We see Martine switching on captions for that video and  adjusting the text size. We also see Martine moving the captions above the video where she can see them better. |
| 4 | 1:15 - 1:40 | In some situations, I find myself needing to lip read. For example, when I'm on unplanned calls without interpreters or other people who can sign. I learned lip reading over the years because of such situations but it's not accurate and very exhausting. I also need to see the person's face and have them speak slowly and clearly. It's not really something you can keep doing for long. | [New scene.] We see Martine in a video conference meeting with multiple people online, similar to that in scene #2. This time, there are no sign language interpreters present. She is focusing on the mouth of the person speaking. She is trying to understand what they are saying but the person is sometimes turning away from the camera (e.g. to point at a board or otherwise gesture). Martine is looking increasingly tired. |
| 5 | 1:40 - 2:05 | Of course, the classes also come with a whole lot of reading. I'm fine with that, except when the writing is unnecessarily complex and without structure like lists and headings. People don't realize that I'm constantly translating text into sign, which is my primary language. So, like just about everyone else, I prefer clear and simple writing. | [New scene.] We see Martine having difficulty understanding a page with with long and justified paragraphs, little spacing, few headings that are hardly distinguishable, and without any structure. |
| 6 | 2:05 - 2:10 | All these issues have one thing in common: your design can include or exclude people! [New scene.] We see Martine signing directly to us, as in the first scene (documentary style into the camera) [in the same style and continuing the first scene]. |
